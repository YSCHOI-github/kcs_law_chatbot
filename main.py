import streamlit as st                     # ì›¹ ì¸í„°í˜ì´ìŠ¤ ì œì‘ì„ ìœ„í•œ Streamlit
import google.generativeai as genai        # Google Gemini AI APIë¥¼ í†µí•œ í…ìŠ¤íŠ¸ ìƒì„± ê¸°ëŠ¥
from dotenv import load_dotenv             # í™˜ê²½ë³€ìˆ˜ ë¡œë“œë¥¼ ìœ„í•œ ëª¨ë“ˆ
import os                                   # ìš´ì˜ì²´ì œ ê´€ë ¨ ê¸°ëŠ¥ ì‚¬ìš©
from pdf_utils import extract_text_from_pdf # PDF ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ê¸°ëŠ¥
import asyncio                              # ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ asyncio ë¼ì´ë¸ŒëŸ¬ë¦¬
from concurrent.futures import ThreadPoolExecutor  # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ThreadPoolExecutor
import numpy as np                          # ìˆ˜ì¹˜ ê³„ì‚°ìš© Numpy ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.feature_extraction.text import TfidfVectorizer  # í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë²¡í„°í™”í•˜ê¸° ìœ„í•œ TF-IDF ë„êµ¬
from sklearn.metrics.pairwise import cosine_similarity       # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ í•¨ìˆ˜

# --- í™˜ê²½ ë³€ìˆ˜ ë° Gemini API ì„¤ì • ---
load_dotenv()
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
genai.configure(api_key=GOOGLE_API_KEY)

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë²•ë ¹ í†µí•© ì±—ë´‡",
    page_icon="ğŸ“š",
    layout="wide"
)

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'law_data' not in st.session_state:
    st.session_state.law_data = {}
if 'selected_category' not in st.session_state:
    st.session_state.selected_category = None
if 'last_used_category' not in st.session_state:
    st.session_state.last_used_category = None
# ì„ë² ë”© ìºì‹±ìš© ìƒíƒœ
if 'embedding_data' not in st.session_state:
    st.session_state.embedding_data = {}
# ì¬ì‚¬ìš© ê°€ëŠ¥í•œ asyncio ì´ë²¤íŠ¸ ë£¨í”„
if 'event_loop' not in st.session_state:
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    st.session_state.event_loop = loop

# ë²•ë ¹ ì¹´í…Œê³ ë¦¬ ë° PDF íŒŒì¼ ê²½ë¡œ
LAW_CATEGORIES = {
    "ê´€ì„¸ë²•": {
        "ê´€ì„¸ë²•": "laws/ê´€ì„¸ë²•.pdf",
        "ê´€ì„¸ë²• ì‹œí–‰ë ¹": "laws/ê´€ì„¸ë²• ì‹œí–‰ë ¹.pdf",
        "ê´€ì„¸ë²• ì‹œí–‰ê·œì¹™": "laws/ê´€ì„¸ë²• ì‹œí–‰ê·œì¹™.pdf",
        "ê´€ì„¸í‰ê°€ ìš´ì˜ì— ê´€í•œ ê³ ì‹œ": "laws/ê´€ì„¸í‰ê°€ ìš´ì˜ì— ê´€í•œ ê³ ì‹œ.pdf",
        "ê´€ì„¸ì¡°ì‚¬ ìš´ì˜ì— ê´€í•œ í›ˆë ¹": "laws/ê´€ì„¸ì¡°ì‚¬ ìš´ì˜ì— ê´€í•œ í›ˆë ¹.pdf",
        "Customs_Valuation_Archer": "laws/customs_valuation_archer.pdf",
    },
    "ììœ ë¬´ì—­í˜‘ì •": {
        "ì›ì‚°ì§€ì¡°ì‚¬ ìš´ì˜ì— ê´€í•œ í›ˆë ¹": "laws/ì›ì‚°ì§€ì¡°ì‚¬ ìš´ì˜ì— ê´€í•œ í›ˆë ¹.pdf",
        "ììœ ë¬´ì—­í˜‘ì • ì›ì‚°ì§€ì¸ì¦ìˆ˜ì¶œì ìš´ì˜ì— ê´€í•œ ê³ ì‹œ": "laws/ììœ ë¬´ì—­í˜‘ì • ì›ì‚°ì§€ì¸ì¦ìˆ˜ì¶œì ìš´ì˜ì— ê´€í•œ ê³ ì‹œ.pdf",
        "íŠ¹ë¡€ë²• ì‚¬ë¬´ì²˜ë¦¬ì— ê´€í•œ ê³ ì‹œ": "laws/ììœ ë¬´ì—­í˜‘ì •ì˜ ì´í–‰ì„ ìœ„í•œ ê´€ì„¸ë²•ì˜ íŠ¹ë¡€ì— ê´€í•œ ë²•ë¥  ì‚¬ë¬´ì²˜ë¦¬ì— ê´€í•œ ê³ ì‹œ.pdf",
        "íŠ¹ë¡€ë²• ì‹œí–‰ê·œì¹™": "laws/ììœ ë¬´ì—­í˜‘ì •ì˜ ì´í–‰ì„ ìœ„í•œ ê´€ì„¸ë²•ì˜ íŠ¹ë¡€ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ê·œì¹™.pdf",
        "íŠ¹ë¡€ë²• ì‹œí–‰ë ¹": "laws/ììœ ë¬´ì—­í˜‘ì •ì˜ ì´í–‰ì„ ìœ„í•œ ê´€ì„¸ë²•ì˜ íŠ¹ë¡€ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹.pdf",
        "íŠ¹ë¡€ë²•": "laws/ììœ ë¬´ì—­í˜‘ì •ì˜ ì´í–‰ì„ ìœ„í•œ ê´€ì„¸ë²•ì˜ íŠ¹ë¡€ì— ê´€í•œ ë²•ë¥ .pdf"
    },
    "ì™¸êµ­í™˜ê±°ë˜": {
        "ì™¸êµ­í™˜ê±°ë˜ë²•": "laws/ì™¸êµ­í™˜ê±°ë˜ë²•.pdf",
        "ì™¸êµ­í™˜ê±°ë˜ë²• ì‹œí–‰ë ¹": "laws/ì™¸êµ­í™˜ê±°ë˜ë²• ì‹œí–‰ë ¹.pdf", 
        "ì™¸êµ­í™˜ê±°ë˜ê·œì •": "laws/ì™¸êµ­í™˜ê±°ë˜ê·œì •.pdf"
    }
}

# PDF ë¡œë“œ ë° ì„ë² ë”© ìƒì„± í•¨ìˆ˜
@st.cache_data
def load_law_data(category=None):
    law_data = {}
    missing_files = []
    if category:
        pdf_files = LAW_CATEGORIES[category]
    else:
        pdf_files = {}
        for cat in LAW_CATEGORIES.values():
            pdf_files.update(cat)
    for law_name, pdf_path in pdf_files.items():
        if os.path.exists(pdf_path):
            text = extract_text_from_pdf(pdf_path)
            law_data[law_name] = text
            # ì„ë² ë”© ìƒì„± ë° ìºì‹±
            vec, mat, chunks = create_embeddings_for_text(text)
            st.session_state.embedding_data[law_name] = (vec, mat, chunks)
        else:
            missing_files.append(pdf_path)
    if missing_files:
        st.warning(f"ë‹¤ìŒ íŒŒì¼ë“¤ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_files)}")
    return law_data

# ì„ë² ë”© ë° ì²­í¬ ìƒì„±
def create_embeddings_for_text(text, chunk_size=1000):
    chunks = []
    step = chunk_size // 2
    for i in range(0, len(text), step):
        segment = text[i:i+chunk_size]
        if len(segment) > 100:
            chunks.append(segment)
    vectorizer = TfidfVectorizer()
    matrix = vectorizer.fit_transform(chunks)
    return vectorizer, matrix, chunks

# ì¿¼ë¦¬ ìœ ì‚¬ ì²­í¬ ê²€ìƒ‰
def search_relevant_chunks(query, vectorizer, tfidf_matrix, text_chunks, top_k=3, threshold=0.005):
    q_vec = vectorizer.transform([query])
    sims = cosine_similarity(q_vec, tfidf_matrix).flatten()
    indices = sims.argsort()[-top_k:][::-1]
    sel = [text_chunks[i] for i in indices if sims[i] > threshold]
    if not sel:
        sel = [text_chunks[i] for i in indices]
    return "\n\n".join(sel)

# Gemini ëª¨ë¸ ë°˜í™˜
def get_model():
    return genai.GenerativeModel('gemini-2.0-flash')

# ë²•ë ¹ë³„ ì—ì´ì „íŠ¸ ì‘ë‹µ (async)
async def get_law_agent_response_async(law_name, question, history):
    vec, mat, chunks = st.session_state.embedding_data[law_name]
    context = search_relevant_chunks(question, vec, mat, chunks)
    prompt = f"""
ë‹¹ì‹ ì€ {law_name} ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë²•ë ¹ ë‚´ìš©ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ë‹¤ìŒ ë²•ë ¹ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:
{context}

ì´ì „ ëŒ€í™”:
{history}

ì§ˆë¬¸: {question}
ë‹µë³€í•  ë•Œ ë²•ì¡°í•­ê³¼ ì¶œì²˜ë¥¼ ëª…í™•íˆ ì œì‹œí•´ì£¼ì„¸ìš”.
"""
    model = get_model()
    loop = st.session_state.event_loop
    with ThreadPoolExecutor() as pool:
        res = await loop.run_in_executor(pool, lambda: model.generate_content(prompt))
    return law_name, res.text

# ëª¨ë“  ì—ì´ì „íŠ¸ ë³‘ë ¬ ì‹¤í–‰
async def gather_agent_responses(question, history):
    tasks = [get_law_agent_response_async(name, question, history)
             for name in st.session_state.law_data]
    return await asyncio.gather(*tasks)

# í—¤ë“œ ì—ì´ì „íŠ¸ í†µí•© ë‹µë³€
def get_head_agent_response(responses, question, history):
    combined = "\n\n".join([f"=== {n} ì „ë¬¸ê°€ ë‹µë³€ ===\n{r}" for n, r in responses])
    prompt = f"""
ë‹¹ì‹ ì€ ë²•ë ¹ í†µí•© ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

{combined}

ì´ì „ ëŒ€í™”:
{history}

ì§ˆë¬¸: {question}

ë‹¤ìŒ ë‹¨ê³„ì— ë”°ë¼ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”:

1. ì§ˆë¬¸ ë¶„ì„
   - ì§ˆë¬¸ì˜ í•µì‹¬ ì£¼ì œ íŒŒì•…
   - í•„ìš”í•œ ë²•ë ¹ ì˜ì—­ ì‹ë³„
   - ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ

2. ë²•ë ¹ ê²€ìƒ‰
   - ê´€ë ¨ ë²•ë ¹ ì¡°í•­ ì°¾ê¸°
   - ë²•ë ¹ ê°„ ì—°ê´€ì„± ë¶„ì„
   - ì ìš© ê°€ëŠ¥í•œ ì˜ˆì™¸ ì¡°í•­ í™•ì¸

3. í•´ì„ ë° ì ìš©
   - ë²•ë ¹ì˜ êµ¬ì²´ì ì¸ ë‚´ìš© í•´ì„
   - ì‹¤ì œ ì‚¬ë¡€ì— ì ìš© ë°©ì•ˆ ê²€í† 
   - ì˜ˆì™¸ ìƒí™© ê³ ë ¤

4. ë‹µë³€ êµ¬ì„±
   - ë²•ë ¹ ê·¼ê±° ëª…ì‹œ, ë°˜ë“œì‹œ ì£¼ì–´ì§„ ë²•ë ¹ì— ê¸°ë°˜í•˜ì—¬ ë‹µë³€ë³€
   - ë‹¨ê³„ë³„ ì„¤ëª… ì œê³µ
   - í•„ìš”í•œ ê²½ìš° ì˜ˆì‹œ ì œì‹œ

ìœ„ êµ¬ì¡°ì— ë”°ë¼ ë‹¨ê³„ë³„ ì¶”ë¡ ì„ ëª…í™•íˆ ë³´ì—¬ì£¼ë©´ì„œ ìµœì¢… í†µí•© ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
    return get_model().generate_content(prompt).text

# --- UI: ì¹´í…Œê³ ë¦¬ ì„ íƒ ---
with st.expander("ì¹´í…Œê³ ë¦¬ ì„ íƒ (ì„ íƒì‚¬í•­)", expanded=True):
    c1, c2, c3, c4 = st.columns(4)
    with c1:
        if st.button("ê´€ì„¸ë²•", use_container_width=True):
            st.session_state.selected_category = "ê´€ì„¸ë²•"
            st.session_state.law_data = load_law_data("ê´€ì„¸ë²•")
            st.session_state.last_used_category = "ê´€ì„¸ë²•"
            st.rerun()
    with c2:
        if st.button("ììœ ë¬´ì—­í˜‘ì •", use_container_width=True):
            st.session_state.selected_category = "ììœ ë¬´ì—­í˜‘ì •"
            st.session_state.law_data = load_law_data("ììœ ë¬´ì—­í˜‘ì •")
            st.session_state.last_used_category = "ììœ ë¬´ì—­í˜‘ì •"
            st.rerun()
    with c3:
        if st.button("ì™¸êµ­í™˜ê±°ë˜", use_container_width=True):
            st.session_state.selected_category = "ì™¸êµ­í™˜ê±°ë˜"
            st.session_state.law_data = load_law_data("ì™¸êµ­í™˜ê±°ë˜")
            st.session_state.last_used_category = "ì™¸êµ­í™˜ê±°ë˜"
            st.rerun()
    with c4:
        if st.button("ìë™ ë¶„ì„", use_container_width=True):
            st.session_state.selected_category = None
            st.session_state.law_data = load_law_data()
            st.session_state.last_used_category = "all"
            st.rerun()

if st.session_state.selected_category:
    st.info(f"ì„ íƒëœ ì¹´í…Œê³ ë¦¬: {st.session_state.selected_category}")
else:
    st.info("ì¹´í…Œê³ ë¦¬ ì„ íƒ ì—†ì´ ìë™ ë¶„ì„ ì¤‘...")

# ëŒ€í™” ê¸°ë¡ ë Œë”ë§
for msg in st.session_state.chat_history:
    with st.chat_message(msg['role']):
        st.markdown(msg['content'])

# ì‚¬ìš©ì ì…ë ¥ ë° ì‘ë‹µ
if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    with st.chat_message("assistant"):
        history = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.chat_history])
        responses = st.session_state.event_loop.run_until_complete(
            gather_agent_responses(user_input, history)
        )
        answer = get_head_agent_response(responses, user_input, history)
        st.markdown(answer)
        st.session_state.chat_history.append({"role": "assistant", "content": answer})

# ì‚¬ì´ë“œë°” ì•ˆë‚´
with st.sidebar:
    st.markdown("""
### â„¹ï¸ ì‚¬ìš© ì•ˆë‚´

ë‹¤ìŒ ë²•ë ¹ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤:

**ê´€ì„¸ë²• ê´€ë ¨:**
- ê´€ì„¸ë²•
- ê´€ì„¸ë²• ì‹œí–‰ë ¹
- ê´€ì„¸ë²• ì‹œí–‰ê·œì¹™
- ê´€ì„¸í‰ê°€ ìš´ì˜ì— ê´€í•œ ê³ ì‹œ
- ê´€ì„¸ì¡°ì‚¬ ìš´ì˜ì— ê´€í•œ í›ˆë ¹
- Customs_Valuation_Archer

**ììœ ë¬´ì—­í˜‘ì • ê´€ë ¨:**
- ì›ì‚°ì§€ì¡°ì‚¬ ìš´ì˜ì— ê´€í•œ í›ˆë ¹
- ììœ ë¬´ì—­í˜‘ì • ì›ì‚°ì§€ì¸ì¦ìˆ˜ì¶œì ìš´ì˜ì— ê´€í•œ ê³ ì‹œ
- ììœ ë¬´ì—­í˜‘ì •ì˜ ì´í–‰ì„ ìœ„í•œ ê´€ì„¸ë²•ì˜ íŠ¹ë¡€ì— ê´€í•œ ë²•ë¥ 
- ììœ ë¬´ì—­í˜‘ì •ì˜ ì´í–‰ì„ ìœ„í•œ ê´€ì„¸ë²•ì˜ íŠ¹ë¡€ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹
- ììœ ë¬´ì—­í˜‘ì •ì˜ ì´í–‰ì„ ìœ„í•œ ê´€ì„¸ë²•ì˜ íŠ¹ë¡€ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ê·œì¹™
- ììœ ë¬´ì—­í˜‘ì •ì˜ ì´í–‰ì„ ìœ„í•œ ê´€ì„¸ë²•ì˜ íŠ¹ë¡€ì— ê´€í•œ ë²•ë¥  ì‚¬ë¬´ì²˜ë¦¬ì— ê´€í•œ ê³ ì‹œ

**ì™¸êµ­í™˜ê±°ë˜ ê´€ë ¨:**
- ì™¸êµ­í™˜ê±°ë˜ë²•
- ì™¸êµ­í™˜ê±°ë˜ë²• ì‹œí–‰ë ¹
- ì™¸êµ­í™˜ê±°ë˜ê·œì •
""")
    if st.button("ìƒˆ ì±„íŒ… ì‹œì‘", type="primary"):
        st.session_state.chat_history = []
        st.rerun()